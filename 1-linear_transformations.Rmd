---
title: "Hands on session 1: Linear Transformations"
author: "Ferran Muiños and Ramon Massoni-Badosa"
date: "7/2/2020"
output: 
  BiocStyle::html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = "100%", fig.align='center', 
                      message=FALSE, warning = FALSE)
options(width = 1200)
```


Objective: learn the interconnexion between rank, dim(N(A)), determinant, invertivility in the light of the geometric interpretation of linear maps.

Reminder:

- Algebraic explanation of linear maps: from matrices to basis vectors or vice versa.
- Definition of null space, rank, column space, inverse and determinant.
- Show algebraically: (1) column vectors linearly independent iff N(A) = 0, (2) inverse only exists if column vectors are linearly independent.

Geometric intuition of linear maps: shiny app

- Linear map: (1) you can think it as a function: something that takes an input and produces and output. (2) you can represent it as a matrix --> 1a pestanya shiny app.
- Show a specific case, with a specific point and matrix (ie 1, 1 , 1, 1; blue point).
- Explain that we can abstract and think about the column space as the output.
- Show 4 examples (2D/3D; linearly dependent / independent): how do all the concepts explained above interconnect in the light of linear maps?

Reverse engineer linear maps:

5-7 small exercises: find a way to make it interactive!! so that they can input the results and we get them and then we share and explain them.


Linear algebra with R

- basic matrix algebra
- Heatmaps: pheatmap, ComplexHeatmap


# Introduction

The objective of this document is to brainstorm and describe the 3 hands-on sessions in linear algebra of the course "Elements of Mathematics" in the Master in Bioinformatics for Health Sciences at UPF. The preliminary titles for the sessions are the following:

- Linear transformations and the fundamental theorem of linear algebra.
- Projections onto subspaces and least squares.
- Singular Value Decomposition and Principal Component Analysis.

More broadly, the objectives of these sessions will be:

- Illustrate the geometric intuition behind the most important linear algebra topics and algorithms covered in the course. To this end, we will use dynamic and interactive visualizations with [shiny](https://shiny.rstudio.com/) and [plotly](https://plotly.com/r/).
- Proof some of these theorems. Besides understanding the geometry, we aim to provide students with enough confidence to demonstrate and reach conclusions from scratch.
- Showcase the usability of linear algebra in real-world biological problems. More specifically, we will show how orthogonal projections and SVD are used to derive least squares regression lines and PCA, respectively.
- Teach how to perform and visualize linear algebra computations with [R](https://www.r-project.org/about.html), an open-source programming language widely used in statistics and genomics.


# Sessions

## Linear transformations and the fundamental theorem of linear algebra

### Pre-requisites

#### Material
One week before the session, students should check this material and be familiar with the corresponding concepts:

Linear transformations describe functions that map vectors from one space to another, and they are described using matrices. Watch:

- [Linear transformations and matrices, by 3blue1brown](https://www.youtube.com/watch?v=kYB8IZa5AuE&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=3).
- [Guess the matrix that describes the transformation](https://en.khanacademy.org/math/linear-algebra/matrix-transformations/linear-transformations/a/practice-associating-matrices-with-transformations).

Matrix multiplication describe composition of function. That is, the linear map described by the product of two matrices equals the linear maps applied by the 2 matrices independently and successively. Watch:

- [Matrix multiplication as composition](https://www.youtube.com/watch?v=XkY2DOUCWMU&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=4)

If and only if the column vectors of a matrix are linearly independent, then the null space contains only the 0 vector. Watch:

- [More on linear independence](https://en.khanacademy.org/math/linear-algebra/vectors-and-spaces/linear-independence/v/more-on-linear-independence)
- [Relation between linear independence and null space](https://en.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/null-space-3-relation-to-linear-independence)

Also, check that you can access the following shiny app:

[https://massonix.shinyapps.io/linear_transformations/](https://massonix.shinyapps.io/linear_transformations/)


#### Install software

- [R 4.0](https://cran.r-project.org/doc/manuals/r-devel/R-admin.html)
- [Rstudio](https://rstudio.com/products/rstudio/download/)
- [Bioconductor](https://www.bioconductor.org/install/)
- [pHeatmap](https://cran.r-project.org/web/packages/pheatmap/pheatmap.pdf)
- [Seurat](https://cran.r-project.org/web/packages/Seurat/index.html)
- [SeuratData](https://github.com/satijalab/seurat-data)


### Objectives

- Grasp the geometry behind linear transformation.
- Create the matrix that defines a basic linear transformation.
- Understand matrix multiplication as composition of linear maps.
- Derive the fundamental theorem of linear algebra (dim(C(A) + dim(N(A)) = n))
- Comprehend relation between rank, null space, determinant and invertibility.
- Create, subset, join and visualize matrices in R. Perform basic linear algebra operations (addition, multiplication, etc.)


### Description of the session

#### Reminder of linear transformations (~10 min)

Here, we will reinforce the main conclusions of the class that explained linear maps. Most important, we want to give a clear understanding of this three properties:

1. A linear map is completely defined by where it takes the basis vectors.
2. Ax = x1·a1 + x2·a2 + ... + xn·an = b: Think of matrix-vector product as a linear combination of the column vectors of A defined by the coordinates of x.
3. A determinant can be understood as the factor by which a unit of "space" (space = segment, square, cube, etc.) is multiplied after a linear map is applied.


#### Shiny app walkthrough (~5 min)

Show the students how to use the [shiny app](https://massonix.shinyapps.io/linear_transformations/).

Show a network that connects the following concepts: determinant, rank, dimension null space, invertibility, column space.


#### Reverse engineer linear maps (~1h)

SHOW a practical example!! INTRODUCE GAUSS JORDAN!

WAY TO SUBMIT A MATRIX AND WE CAN MAKE IT INTERACTIVE!!! MEMO??

Once they understand the concepts of linear map and know how to use the app, students should be able to guess the matrix A that describes basic linear transformations. Moreover, we want to build the intuition for how the concepts of rank, null space, determinant and invertibility interact. Here are some examples of basic transformations they could perform:

Create a matrix A that...

1. expands space by a factor of 2 in all axis.
2. shrinks space to half its initial value
3. reflects every vector across the x = y line
4. rotates every vector by 30º (hint: use unit circle)
5. Smear

For each transformation, they should be able to answer these questions:

- Which is the determinant of A?
- Which is the dimension of the null space?
- Is the matrix invertible?
- Are the column vectors linearly independent?


Secondly, students should be able to compose linear transformations using matrix multiplication. For instance, they should check that the product of the following matrices is the same as applying them separately:

- Shrinkage + reflection
- Rotation + Smear

Challenge: ask them if order matters. In other words, is the final transformation the same for AB than for BA? Use this example to make the point that matrix multiplication is not usually commutative.

Finally, students should be able to create linear transformations that achieve the following:

- 2D: Square --> line
- 3D: Cube --> plane
- 3D: Cube --> line


#### Fundamental Theorem Linear Algebra via Gauss-Jordan

TBD

#### Matrix algebra with R (~45 min)

This section aims to teach the fundamentals of R to be able to perform linear algebra operations and visualize them. We will start by teaching the basic data structures, categorized by dimensionality (1D: atomic vectors + lists; 2D: matrices + data.frames) and whether they can contain only one value type (homogenous: atomic vectors and matrices) or more than one (heterogeneous: lists and data.frames). Moreover, here I showcase an example of the main functions we should cover in the hands-on session:



```{r}
# Load packages
library(Seurat)
library(SeuratData)
library(pheatmap)


# Create
x <- c(1, 2, 3)
A <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9), nrow = 3, ncol = 3, byrow = FALSE)
x 
A


# Get dimensions
length(x)
dim(A)
nrow(A)
ncol(A)


# Name
names(x) <- c("1", "2", "3")
rownames(A) <- c("a", "b", "c")
colnames(A) <- c("x", "y", "z")
x
A

# Subset
## Numeric
x[1]
x[c(2, 3)]
x[c(3, 3)]
A[1:3, -2]

## Character
x["b"]
A[c("a", "b"), ]

## Logical
x[c(FALSE, TRUE, TRUE)]
x > 1
x[x > 1]


# Concatenate
rbind(A, x)
cbind(A, x)


# Transpose
t(A)


# Matrix-vector operations
A + x
A * x
A %*% x
t(x[1] %*% A[, 1]) + t(x[2] %*% A[, 2]) + t(x[3] %*% A[, 3])

# Matrix-Matrix operations
A + A
A * A
A %*% A


# Heatmap
# InstallData("panc8")
# data("panc8")
# scRNA_seq_mat <- as.matrix(panc8[["RNA"]]@data)
# pheatmap(
#   scRNA_seq_mat,
#   cluster_cols = FALSE,
#   cluster_rows = FALSE,
#   labels_col = FALSE,
#   labels_row = FALSE
# )
```
